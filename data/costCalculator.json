{
  "currencies": {
    "USD": {
      "symbol": "$",
      "name": "US Dollar",
      "code": "USD",
      "rate": 1.0,
      "position": "before",
      "decimalPlaces": 2
    },
    "EUR": {
      "symbol": "€",
      "name": "Euro",
      "code": "EUR",
      "rate": 0.92,
      "position": "before",
      "decimalPlaces": 2
    },
    "GBP": {
      "symbol": "£",
      "name": "British Pound",
      "code": "GBP",
      "rate": 0.79,
      "position": "before",
      "decimalPlaces": 2
    },
    "JPY": {
      "symbol": "¥",
      "name": "Japanese Yen",
      "code": "JPY",
      "rate": 149.50,
      "position": "before",
      "decimalPlaces": 0
    },
    "CAD": {
      "symbol": "C$",
      "name": "Canadian Dollar",
      "code": "CAD",
      "rate": 1.36,
      "position": "before",
      "decimalPlaces": 2
    },
    "AUD": {
      "symbol": "A$",
      "name": "Australian Dollar",
      "code": "AUD",
      "rate": 1.53,
      "position": "before",
      "decimalPlaces": 2
    },
    "CHF": {
      "symbol": "CHF",
      "name": "Swiss Franc",
      "code": "CHF",
      "rate": 0.88,
      "position": "before",
      "decimalPlaces": 2
    },
    "CNY": {
      "symbol": "¥",
      "name": "Chinese Yuan",
      "code": "CNY",
      "rate": 7.24,
      "position": "before",
      "decimalPlaces": 2
    },
    "INR": {
      "symbol": "₹",
      "name": "Indian Rupee",
      "code": "INR",
      "rate": 83.12,
      "position": "before",
      "decimalPlaces": 2
    },
    "BRL": {
      "symbol": "R$",
      "name": "Brazilian Real",
      "code": "BRL",
      "rate": 4.97,
      "position": "before",
      "decimalPlaces": 2
    }
  },
  "usagePresets": [
    {
      "id": "hobby",
      "name": "Hobby / Personal",
      "description": "Light usage for personal projects",
      "tokensPerDay": 50000,
      "requestsPerDay": 50,
      "icon": "user"
    },
    {
      "id": "startup",
      "name": "Startup / Small Business",
      "description": "Growing business with moderate usage",
      "tokensPerDay": 500000,
      "requestsPerDay": 500,
      "icon": "trending-up"
    },
    {
      "id": "enterprise",
      "name": "Enterprise",
      "description": "High-volume production workloads",
      "tokensPerDay": 5000000,
      "requestsPerDay": 5000,
      "icon": "building"
    },
    {
      "id": "custom",
      "name": "Custom",
      "description": "Enter your own usage estimates",
      "tokensPerDay": 0,
      "requestsPerDay": 0,
      "icon": "settings"
    }
  ],
  "costComponents": {
    "inputTokenMultiplier": 1,
    "outputTokenMultiplier": 1,
    "averageInputOutputRatio": 0.3,
    "notes": "Input tokens are typically 30% of total, output 70%"
  },
  "selfHostingCosts": {
    "hardware": [
      {
        "name": "RTX 4090 (24GB)",
        "upfrontCost": 1600,
        "monthlyPower": 45,
        "maxModelSize": "14B",
        "tokensPerSecond": 95,
        "suitable": ["Llama 3.1 8B", "Mistral 7B", "DeepSeek-R1 14B"]
      },
      {
        "name": "2x RTX 4090 (48GB)",
        "upfrontCost": 3200,
        "monthlyPower": 90,
        "maxModelSize": "34B",
        "tokensPerSecond": 32,
        "suitable": ["CodeLlama 34B", "DeepSeek-R1 32B", "Mixtral 8x7B"]
      },
      {
        "name": "M3 Max (128GB)",
        "upfrontCost": 4000,
        "monthlyPower": 12,
        "maxModelSize": "70B",
        "tokensPerSecond": 35,
        "suitable": ["Llama 3.1 70B", "DeepSeek-R1 70B", "Mixtral 8x22B"]
      },
      {
        "name": "M2 Ultra (192GB)",
        "upfrontCost": 7000,
        "monthlyPower": 15,
        "maxModelSize": "671B",
        "tokensPerSecond": 16,
        "suitable": ["DeepSeek-R1 671B", "Llama 405B", "All models"]
      },
      {
        "name": "A100 80GB",
        "upfrontCost": 15000,
        "monthlyPower": 50,
        "maxModelSize": "70B",
        "tokensPerSecond": 85,
        "suitable": ["All models up to 70B", "Production workloads"]
      },
      {
        "name": "H100 80GB",
        "upfrontCost": 30000,
        "monthlyPower": 90,
        "maxModelSize": "70B",
        "tokensPerSecond": 140,
        "suitable": ["High-performance production", "All models"]
      },
      {
        "name": "AMD RX 7900 XTX (24GB)",
        "upfrontCost": 900,
        "monthlyPower": 38,
        "maxModelSize": "14B",
        "tokensPerSecond": 82,
        "suitable": ["Llama 3.1 8B", "Mistral 7B", "DeepSeek-R1 14B"]
      },
      {
        "name": "AMD RX 6900 XT (16GB)",
        "upfrontCost": 550,
        "monthlyPower": 35,
        "maxModelSize": "8B",
        "tokensPerSecond": 68,
        "suitable": ["Llama 3.1 8B", "Mistral 7B", "Phi-3"]
      },
      {
        "name": "2x AMD MI250X (128GB)",
        "upfrontCost": 12000,
        "monthlyPower": 110,
        "maxModelSize": "70B",
        "tokensPerSecond": 95,
        "suitable": ["Enterprise workloads", "All models up to 70B"]
      },
      {
        "name": "AWS g5.xlarge (A10G 24GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 340,
        "maxModelSize": "14B",
        "tokensPerSecond": 75,
        "suitable": ["Cloud-based", "Llama 3.1 8B", "Mistral 7B"],
        "isCloud": true
      },
      {
        "name": "AWS p4d.24xlarge (8x A100)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 24500,
        "maxModelSize": "671B",
        "tokensPerSecond": 650,
        "suitable": ["Enterprise cloud", "All models", "High throughput"],
        "isCloud": true
      },
      {
        "name": "GCP n1-standard-4-v100",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 950,
        "maxModelSize": "14B",
        "tokensPerSecond": 65,
        "suitable": ["Cloud-based", "Cost-effective", "Medium workloads"],
        "isCloud": true
      },
      {
        "name": "Azure NC6s_v3 (V100 16GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 900,
        "maxModelSize": "14B",
        "tokensPerSecond": 70,
        "suitable": ["Azure ecosystem", "Llama 3.1 8B", "Mistral 7B"],
        "isCloud": true
      },
      {
        "name": "RunPod RTX 4090 (24GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 290,
        "maxModelSize": "14B",
        "tokensPerSecond": 95,
        "suitable": ["Budget cloud", "Llama 3.1 8B", "DeepSeek-R1 14B"],
        "isCloud": true
      },
      {
        "name": "Lambda Labs 1x A100 (40GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 792,
        "maxModelSize": "34B",
        "tokensPerSecond": 85,
        "suitable": ["Cost-effective A100", "Llama 3.1 70B", "Medium models"],
        "isCloud": true
      },
      {
        "name": "Lambda Labs 8x A100 (320GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 6336,
        "maxModelSize": "671B",
        "tokensPerSecond": 680,
        "suitable": ["Multi-GPU training", "Large models", "Production"],
        "isCloud": true
      },
      {
        "name": "Lambda Labs 1x H100 (80GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 1793,
        "maxModelSize": "70B",
        "tokensPerSecond": 140,
        "suitable": ["Latest GPU", "High performance", "LLM training"],
        "isCloud": true
      },
      {
        "name": "RunPod A100 80GB",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 1360,
        "maxModelSize": "70B",
        "tokensPerSecond": 90,
        "suitable": ["Large VRAM", "Production workloads"],
        "isCloud": true
      },
      {
        "name": "RunPod H100 80GB",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 2800,
        "maxModelSize": "70B",
        "tokensPerSecond": 140,
        "suitable": ["Cutting-edge", "Fastest inference"],
        "isCloud": true
      },
      {
        "name": "Vast.ai RTX 3090 (24GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 216,
        "maxModelSize": "14B",
        "tokensPerSecond": 70,
        "suitable": ["Ultra budget", "Testing", "Development"],
        "isCloud": true
      },
      {
        "name": "Vast.ai A100 80GB",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 864,
        "maxModelSize": "70B",
        "tokensPerSecond": 90,
        "suitable": ["Budget A100", "Community cloud"],
        "isCloud": true
      },
      {
        "name": "GCP a2-highgpu-1g (A100 40GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 2642,
        "maxModelSize": "34B",
        "tokensPerSecond": 85,
        "suitable": ["GCP ecosystem", "Enterprise", "ML training"],
        "isCloud": true
      },
      {
        "name": "GCP a3-highgpu-8g (8x H100)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 68054,
        "maxModelSize": "671B",
        "tokensPerSecond": 1120,
        "suitable": ["Frontier AI", "Largest workloads", "Enterprise"],
        "isCloud": true
      },
      {
        "name": "Azure ND96asr v4 (8x A100)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 19584,
        "maxModelSize": "671B",
        "tokensPerSecond": 760,
        "suitable": ["Azure enterprise", "Large-scale ML"],
        "isCloud": true
      },
      {
        "name": "Azure ND96isr H100 v5 (8x H100)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 64800,
        "maxModelSize": "671B",
        "tokensPerSecond": 1120,
        "suitable": ["Azure H100", "Cutting-edge AI"],
        "isCloud": true
      },
      {
        "name": "CoreWeave H100 NVLINK",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 3427,
        "maxModelSize": "70B",
        "tokensPerSecond": 140,
        "suitable": ["Specialized AI cloud", "High bandwidth"],
        "isCloud": true
      },
      {
        "name": "CoreWeave 8x H100 NVLINK",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 27418,
        "maxModelSize": "671B",
        "tokensPerSecond": 1120,
        "suitable": ["Multi-GPU", "Frontier AI models"],
        "isCloud": true
      },
      {
        "name": "Paperspace A100 80GB",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 2225,
        "maxModelSize": "70B",
        "tokensPerSecond": 90,
        "suitable": ["Developer-friendly", "Notebooks"],
        "isCloud": true
      },
      {
        "name": "AWS g5.2xlarge (A10G 24GB)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 873,
        "maxModelSize": "14B",
        "tokensPerSecond": 80,
        "suitable": ["AWS ecosystem", "Inference", "Medium workloads"],
        "isCloud": true
      },
      {
        "name": "AWS p5.48xlarge (8x H100)",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 70790,
        "maxModelSize": "671B",
        "tokensPerSecond": 1120,
        "suitable": ["AWS latest", "Frontier AI", "Enterprise"],
        "isCloud": true
      },
      {
        "name": "GCP n1-standard-4 + T4",
        "upfrontCost": 0,
        "monthlyPower": 0,
        "monthlyCloudCost": 468,
        "maxModelSize": "8B",
        "tokensPerSecond": 60,
        "suitable": ["Entry-level", "Inference", "Budget"],
        "isCloud": true
      }
    ],
    "operationalCosts": {
      "powerCostPerKwh": 0.12,
      "maintenanceMonthly": 50,
      "internetMonthly": 100,
      "depreciationYears": 3
    }
  },
  "tips": [
    {
      "title": "Token Estimation",
      "content": "1 token ≈ 4 characters or ≈ 0.75 words. A typical chat message is 50-200 tokens."
    },
    {
      "title": "Input vs Output",
      "content": "For most applications, output tokens are 2-3x more than input tokens due to longer responses."
    },
    {
      "title": "Batch Processing",
      "content": "Some APIs offer batch processing discounts of 50%+ for non-real-time workloads."
    },
    {
      "title": "Self-Hosting ROI",
      "content": "Self-hosting becomes cost-effective at ~$500-1000/month API spend, depending on model size."
    },
    {
      "title": "Hidden Costs",
      "content": "Consider development time, maintenance, monitoring, and DevOps overhead for self-hosted solutions."
    }
  ]
}
